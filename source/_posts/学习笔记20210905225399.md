---
title: 学习笔记20210905225399
date: 2020-09-05 22:53:00
categories: 学习笔记
tags: [大数据]
copyright: true #新增,开启
---

<!--more-->
## Hadoop生态圈基础三件套

#### HDFS
    HDFS是分布式文件系统。hadoop生态圈组件大部分依赖HDFS中存储的数据。由于底层存储一样，往往各个开源组件都是可以数据互通

#### MapReduce
    分布式计算框架/模型。（我们自己写代码的话，通常会分片，并行计算，再合并等，该框架方便我们处理这些非业务问题）

#### Yarn
    资源统一管理与调度平台

通常的用法为：我们利用MapReduce框架写的程序，读取HDFS上文件，当作数据输入进行处理。众多MapReduce程序跑在众多机器上，由yarn进行资源调度

## DAG
通常我们对数据的处理，例如分片，过滤，聚合等操作。都采用类似DAG模型（有向无环图），每个操作相当于有向无环图中的每个节点。

我们可以用流程编排的方式，将每个操作编排起来，也可以借助DAG调度平台实现

## 平台概念
大数据与我们平时的程序驱动方式不太相同。大数据中，处理流程往往是由平台来驱动我们代码；而平时，整个程序是由我们代码自己写控制流程进行驱动

## 离线OLAP框架
离线OLAP通常应用场景是，不要求延迟时间的场景。  
通常有：日志分析，报表生成，其他离线分析型场景

#### TiSpark
    TiSpark既可以批处理，也可流处理

#### Hive
    基于Hadoop的数据仓库，解决海量结构化数据统计问题。支持类似sql的语法（但不支持事务），原理是将sql转化为mapreduce去执行  
    - 倾向于处理结构化数据，要求先声明数据结构，再载入数据
    - 数据仓库，允许增删改查。但是修改和删除，本质是先将文件数据块读出，修改后再存入，代价极大

#### Pig
    与Hive基本一致。  
    - 倾向于处理非结构化数据，允许先载入数据，再声明数据结构
    - 纯粹文件处理，不允许增加修改删除
    - 数据分析语法比Hive略全

有时会Pig，Hive结合使用。利用Pig非结构化数据处理特性清晰数据，Hive在后方做数据分析

## 数据存储/搜索框架

#### Hbase
- 分布式KV存储，方便随机读写访问
- 更新支持能力极好（底层不是直接删除，而是记录数据及时间戳，读取最新数据。）
- 查询性能极好。由于其kv存储，无法做到复杂分析

#### ES
- 更新能力差，由于底层HDFS存储，只能整块修改
- 查询能力强。自身会建立反向索引（索引可常驻内存），且具备复杂分析能力

## 流处理框架

流处理通常运用在，欺诈识别，基于规则的异常告警，业务监控，广告推荐系统，实时分析等场景

#### 流批概念
流处理通常为事件驱动，即收到消息会触发计算。  
批处理会当数据积累到一定数量时再计算。  
两者在延迟和吞吐量有所差别

#### storm
流处理框架，延迟在几毫米->几十毫秒，可保证消息最少被处理一次

#### spark
支持选择流处理或批处理，延迟在秒级，有spark生态支撑。  
流处理的原理是，通过极小的批处理伪装流处理  
spark某种程度上弱于flink，其优点在于建立在spark生态上，需要离线&实时处理结合的场景尤为适合

#### flink
流批一体，延迟几十毫秒->几百毫秒。  
批处理原理是，流处理伪装成批处理

#### samza
强依赖kafka，优点是可以将中间计算结果存储至kafka供下游消费

流处理
## 一些其他工具

#### mahout
是个机器学习库

#### flume
跟logstash功能类似，但侧重点有所差别

#### scoop
在mysql等关系型数据库，与HDFS存储的各种大数据工具中，复制数据

#### zookeeper

#### kafka

## 学习顺序
HDFS->离线->批处理->流处理

## 究竟谁优谁劣
没有绝对上的优劣，各个框架都在飞速发展中，经常会出现互相借鉴的情况。  
有可能过上一段时间，支持特性便有所进步

## 如何看待大数据
大数据仅仅是帮助我们简化代码编写的工具。即使不用大数据，我们也依旧需要按照大数据的方式去处理数据。不必排斥，也不必过度推崇

## 什么时候会需要使用大数据框架
- 由于大数据通常是由平台驱动代码，团队需具备运维能力
- 代码处理时，数据量已经多到需要提前按哈希分批来处理的底部

## 目前自己的疑问
如何基于全部历史数据，来进行实时持续聚合